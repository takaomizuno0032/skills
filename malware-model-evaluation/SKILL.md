---
name: model-evaluation
version: 0.1.0
description: >
    Evaluate and analyze malware classification model outputs by comparing
    them with human analyst reasoning, focusing on misclassification causes,
    missing signals, and limits of model understanding.
triggers:
    - model evaluation
    - misclassification analysis
    - why the model is wrong
    - malware analysis evaluation
    - LLM malware analysis
---

# Model Evaluation Skill

## Purpose

This skill evaluates **malware analysis or classification results**
produced by models (e.g., LLMs) against **human analyst reasoning**.

The goal is not to compute accuracy,
but to understand:

- Why the model produced a given output
- Where its reasoning diverges from a human analyst
- What signals the model over-weighted or ignored

（この Skill は、モデルの正誤判定ではなく、
「なぜその判断に至ったか／至らなかったか」を分析するためのものです）

---

## Expected Input

Provide the following information:

1. **Model Output**
    - Classification result
    - Explanation or rationale (if available)

2. **Human Analyst Judgment**
    - Expected classification
    - Key reasoning points

3. **Behavioral Evidence**
    - Abstract behavioral trace
    - Key signals and negative signals

Example:

```text
Model Output:
- Ransomware (High confidence)

Human Judgment:
- Trojan / Backdoor
- No encryption or user-facing behavior observed

Behavioral Evidence:
- Process injection
- Periodic C2 communication
- No persistence
```
